{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup und Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import sys\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import NaiveBayes, NaiveBayesModel\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Übung 1\n",
    "\n",
    "Erstellen eines neuen SparkContext mit dem Name \"LanguageClassifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printRDD(rdd, part = True):\n",
    "    if (part):\n",
    "        for i in rdd.take(10):\n",
    "            print(i)\n",
    "    else:\n",
    "        for i in rdd.collect():\n",
    "            print(i)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Übung 2\n",
    "\n",
    "Die Methode \"readDataFiles\" ergänzen. Erstelle eine Variable mit dem Namen dataRDD und lade mit dem SparkContext mit der Methode \"wholeTextFiles\" nur den Text in das RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readDataFiles(path):\n",
    "    global sc\n",
    "    return dataRDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"language-classifier-data\"\n",
    "deRDD = readDataFiles(path + \"/de_DE\")\n",
    "enRDD = readDataFiles(path + \"/en_UK\")\n",
    "esRDD = readDataFiles(path + \"/es_ES\")\n",
    "frRDD = readDataFiles(path + \"/fr_FR\")\n",
    "itRDD = readDataFiles(path + \"/it_IT\")\n",
    "nlRDD = readDataFiles(path + \"/nl_NL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printRDD(deRDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Vector erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charset = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'à', 'á', 'â', 'ã', 'ä', 'è', 'é', 'ê', 'ë', 'ì', 'í', 'î', 'ï', 'ñ', 'ò', 'ó', 'ô', 'ö', 'ù', 'ú', 'û', 'ü']\n",
    "print(\"size of character set\", len(charset))\n",
    "\n",
    "bigram_dict = {}\n",
    "idx = 0\n",
    "for c1 in charset:\n",
    "    for c2 in charset:\n",
    "        bigram_dict[c1+c2] = idx\n",
    "        idx += 1\n",
    "\n",
    "print(\"number of bigrams\", len(bigram_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initBigramVector():\n",
    "    return np.zeros(len(bigram_dict), dtype = np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBigramVector(text):\n",
    "    global bigram_dict\n",
    "    bv = initBigramVector()\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(text) - 1:\n",
    "        bigram = text[i].lower() + text[i+1].lower()\n",
    "        if bigram in bigram_dict:\n",
    "            bv[bigram_dict[bigram]] += 1\n",
    "        i += 1\n",
    "    \n",
    "    return bv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "print(getBigramVector(\"Ich bin ein kurzer Text\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train und Test Daten erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRDD = deRDD.map(lambda x: LabeledPoint(0.0, getBigramVector(x))) \\\n",
    "    .union(enRDD.map(lambda x: LabeledPoint(1.0, getBigramVector(x)))) \\\n",
    "    .union(esRDD.map(lambda x: LabeledPoint(2.0, getBigramVector(x)))) \\\n",
    "    .union(frRDD.map(lambda x: LabeledPoint(3.0, getBigramVector(x)))) \\\n",
    "    .union(itRDD.map(lambda x: LabeledPoint(4.0, getBigramVector(x)))) \\\n",
    "    .union(nlRDD.map(lambda x: LabeledPoint(5.0, getBigramVector(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataRDD.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataRDD.first().label)\n",
    "print(dataRDD.first().features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Übung 3\n",
    "\n",
    "Splitte das \"dataRDD\" in ein Test und Train RDD mit dem Namen \"trainingRDD\" und \"testRDD\". Dies kannst du mit randomSplit machen. Das Trainset sollte 80% der Daten beinhalten und das Testset 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klassifizieren und Bewerten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveBayes.train(trainingRDD, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionAndLabels = testRDD.map(lambda lp: (float(model.predict(lp.features)), lp.label))\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "print(\"Accuracy:\",metrics.accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Übung 4\n",
    "\n",
    "Teste den Classifier. Rufe auf dem Model die Methode Predict auf. Zuerst muss der Bigram Vector des Textes ermittelt werden. Dies kannst du mit der Methode \"getBigramVector\" machen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
